{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOn0/uQE/D+FKPVG6awopnY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nuttnice187/crashes/blob/main/sparkudf_cpp_binding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "\n",
        "Binding C++ code to a Spark UDF can yield significant performance gains compared to a standard PySpark UDF, but the actual benefit depends on how you integrate it and the workload characteristics.\n"
      ],
      "metadata": {
        "id": "oxBeHkK2HBL7"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31ce7d14",
        "outputId": "9e093911-3a81-4cb5-a5cb-2143317d5ec1"
      },
      "source": [
        "!pip install pybind11"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pybind11\n",
            "  Downloading pybind11-3.0.2-py3-none-any.whl.metadata (10 kB)\n",
            "Downloading pybind11-3.0.2-py3-none-any.whl (310 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.2/310.2 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pybind11\n",
            "Successfully installed pybind11-3.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "`pybind11` is a lightweight, header-only library that exposes C++ types in Python and vice versa, mainly to create Python bindings of existing C++ code. Essentially, it allows you to call C++ functions and use C++ classes directly from Python, and also to call Python functions from C++.\n",
        "\n",
        "Key features and benefits:\n",
        "\n",
        "*   **Easy to Use:** It's designed to be very simple and intuitive, often requiring only a few lines of C++ code to expose an entire C++ class or function.\n",
        "*   **Header-Only:** You don't need to compile `pybind11` itself; you just include its headers in your C++ project.\n",
        "*   **Modern C++:** It leverages modern C++11 (or newer) features, making the binding code clean and efficient.\n",
        "*   **Automatic Type Conversion:** It automatically handles conversions between many common C++ and Python data types (e.g., `std::vector` to Python lists, `std::string` to Python strings, C++ numbers to Python numbers).\n",
        "*   **Low Overhead:** It's designed for high performance, with minimal overhead when calling between Python and C++."
      ],
      "metadata": {
        "id": "ROo08lqZCY_X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define a function\n",
        "Markdown highlights C++ syntax.\n",
        "\n",
        "```cpp\n",
        "#include <pybind11/pybind11.h>\n",
        "#include <pybind11/stl.h>\n",
        "#include <vector>\n",
        "#include <algorithm> // For std::max_element, std::find\n",
        "\n",
        "bool hasPairSumMaxCpp(const std::vector<int>& elements) {\n",
        "    // Create a mutable copy of the input elements vector.\n",
        "    std::vector<int> mutable_elements = elements;\n",
        "\n",
        "    // If the vector has fewer than 2 elements, no pair can be formed.\n",
        "    if (mutable_elements.size() < 2) {\n",
        "        return false;\n",
        "    }\n",
        "\n",
        "    // Find the maximum element in the copied vector.\n",
        "    int max_val = *std::max_element(mutable_elements.begin(), mutable_elements.end());\n",
        "\n",
        "    // Remove the first occurrence of this maximum element from the copied vector.\n",
        "    auto it = std::find(mutable_elements.begin(), mutable_elements.end(), max_val);\n",
        "    if (it != mutable_elements.end()) {\n",
        "        mutable_elements.erase(it);\n",
        "    }\n",
        "\n",
        "    // After removing the max, check if we still have at least two elements to form a pair\n",
        "    if (mutable_elements.size() < 2) {\n",
        "        return false;\n",
        "    }\n",
        "\n",
        "    // Iterate through the remaining elements in the modified vector using nested loops.\n",
        "    // Check if any two distinct elements sum up to the previously identified maximum element.\n",
        "    for (size_t i = 0; i < mutable_elements.size(); ++i) {\n",
        "        for (size_t j = i + 1; j < mutable_elements.size(); ++j) {\n",
        "            if (mutable_elements[i] + mutable_elements[j] == max_val) {\n",
        "                // If such a pair is found, return true immediately.\n",
        "                return true;\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // If no such pair is found after checking all possibilities, return false.\n",
        "    return false;\n",
        "}\n",
        "\n",
        "namespace py = pybind11;\n",
        "\n",
        "PYBIND11_MODULE(lib, m) {\n",
        "    m.doc() = \"pybind11 example plugin\"; // optional module docstring\n",
        "\n",
        "    // Update the m.def line for has_pair_sum_max_cpp to reflect the new signature and docstring.\n",
        "    m.def(\"has_pair_sum_max_cpp\", &hasPairSumMaxCpp, \"Check if two distinct elements in the list sum up to the list's maximum, excluding one instance of the maximum itself.\");\n",
        "}\n",
        "```"
      ],
      "metadata": {
        "id": "XW9f7jq7CeBa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Python code highlight styling can make C++ hard to read. The `%%writefile <file_name>` command is a Jupyter (and thus Colab) cell magic.  Its primary purpose is to write the entire content of the cell, excluding the `%%writefile` line itself, to a specified file."
      ],
      "metadata": {
        "id": "4ajyMSrEYpBH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Write C++ pybind plugin, `lib.cpp`\n",
        "%%writefile lib.cpp\n",
        "#include <pybind11/pybind11.h>\n",
        "#include <pybind11/stl.h>\n",
        "#include <vector>\n",
        "#include <algorithm> // For std::max_element, std::find\n",
        "\n",
        "bool hasPairSumMaxCpp(const std::vector<int>& elements) {\n",
        "    // Create a mutable copy of the input elements vector.\n",
        "    std::vector<int> mutable_elements = elements;\n",
        "\n",
        "    // If the vector has fewer than 2 elements, no pair can be formed.\n",
        "    if (mutable_elements.size() < 2) {\n",
        "        return false;\n",
        "    }\n",
        "\n",
        "    // Find the maximum element in the copied vector.\n",
        "    int max_val = *std::max_element(mutable_elements.begin(), mutable_elements.end());\n",
        "\n",
        "    // Remove the first occurrence of this maximum element from the copied vector.\n",
        "    auto it = std::find(mutable_elements.begin(), mutable_elements.end(), max_val);\n",
        "    if (it != mutable_elements.end()) {\n",
        "        mutable_elements.erase(it);\n",
        "    }\n",
        "\n",
        "    // After removing the max, check if we still have at least two elements to form a pair\n",
        "    if (mutable_elements.size() < 2) {\n",
        "        return false;\n",
        "    }\n",
        "\n",
        "    // Iterate through the remaining elements in the modified vector using nested loops.\n",
        "    // Check if any two distinct elements sum up to the previously identified maximum element.\n",
        "    for (size_t i = 0; i < mutable_elements.size(); ++i) {\n",
        "        for (size_t j = i + 1; j < mutable_elements.size(); ++j) {\n",
        "            if (mutable_elements[i] + mutable_elements[j] == max_val) {\n",
        "                // If such a pair is found, return true immediately.\n",
        "                return true;\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // If no such pair is found after checking all possibilities, return false.\n",
        "    return false;\n",
        "}\n",
        "\n",
        "namespace py = pybind11;\n",
        "\n",
        "PYBIND11_MODULE(lib, m) {\n",
        "    m.doc() = \"pybind11 example plugin\"; // optional module docstring\n",
        "\n",
        "    // Update the m.def line for has_pair_sum_max_cpp to reflect the new signature and docstring.\n",
        "    m.def(\"has_pair_sum_max_cpp\", &hasPairSumMaxCpp, \"Check if two distinct elements in the list sum up to the list's maximum, excluding one instance of the maximum itself.\");\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8afKZ8s70ma",
        "outputId": "16f57a8a-dbf7-448a-e642-60fdd2e2c588",
        "cellView": "form"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing lib.cpp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The content directory shows the `.cpp` file."
      ],
      "metadata": {
        "id": "pWQw8S5QPD4c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "pwd\n",
        "ls -a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Vf5eGDzvQ0O",
        "outputId": "cf34948d-8fee-4e6c-aaac-a2fc81449edb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            ".\n",
            "..\n",
            ".config\n",
            "lib.cpp\n",
            "sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build, compile shared-object module"
      ],
      "metadata": {
        "id": "O0ILDSHUBwDo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!g++ --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1NsQz0P_acV",
        "outputId": "b26763a2-6da9-478a-e033-458d236a9fb5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "g++ (Ubuntu 11.4.0-1ubuntu1~22.04.2) 11.4.0\n",
            "Copyright (C) 2021 Free Software Foundation, Inc.\n",
            "This is free software; see the source for copying conditions.  There is NO\n",
            "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `g++` is the GNU C++ compiler, used in Bash to compile C++ source files into executables. It handles preprocessing, compilation, assembly, and linking in one step unless instructed otherwise.\n",
        "\n"
      ],
      "metadata": {
        "id": "dCFe31I3ytMK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "g++ -O3 -Wall -shared -std=c++17 -fPIC \\\n",
        "-I/usr/include/python3.12 \\\n",
        "-I/usr/local/lib/python3.12/dist-packages/pybind11/include lib.cpp \\\n",
        "-o lib.cpython-312-x86_64-linux-gnu.so"
      ],
      "metadata": {
        "id": "vyioKz5bp7He"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's compiling your `lib.cpp` file into a Python-compatible shared library. Here's a breakdown of the command:\n",
        "\n",
        "*   `-O3`: This flag enables a high level of optimization, aiming for faster execution of the compiled code.\n",
        "*   `-Wall`: This flag turns on all common warning messages, which helps catch potential issues in the C++ code during compilation.\n",
        "*   `-shared`: This is crucial for creating a shared library (also known as a shared object or `.so` file on Linux). Shared libraries can be dynamically linked by other programs, like Python in this case.\n",
        "*   `-std=c++17`: Specifies that the C++ code should be compiled using the C++17 standard, which enables features introduced in that version of the language.\n",
        "*   `-fPIC`: Stands for \"Position-Independent Code.\" This is necessary when creating shared libraries, as it allows the code to be loaded at any memory address without modification.\n",
        "*   `-I/usr/include/python3.12`: This flag adds the Python 3.12 include directory to the search path for header files. This is needed because `pybind11` relies on Python's C API.\n",
        "*   `-I/usr/local/lib/python3.12/dist-packages/pybind11/include`: This adds the `pybind11` library's include directory to the search path, allowing the compiler to find `pybind11` headers.\n",
        "*   `lib.cpp`: This is the input C++ source file that contains your `pybind11` module definition.\n",
        "*   `-o lib.cpython-312-x86_64-linux-gnu.so`: This specifies the output file name for the compiled shared library. The naming convention `lib.<python_abi_tag>.so` (e.g., `lib.cpython-312-x86_64-linux-gnu.so`) is typical for Python extension modules, allowing Python to discover and import it as a module named `lib`."
      ],
      "metadata": {
        "id": "H9V8-faw8WMC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "pwd\n",
        "ls -a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYr4zcOip-jO",
        "outputId": "2b4eaa17-ede1-4437-a2b5-dee1a7c01940"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            ".\n",
            "..\n",
            ".config\n",
            "lib.cpp\n",
            "lib.cpython-312-x86_64-linux-gnu.so\n",
            "sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The content directory shows the `.so` file."
      ],
      "metadata": {
        "id": "kNoCoIWJP2ZL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import built-in function from module"
      ],
      "metadata": {
        "id": "9A8nmFOFClPT"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "170ba4e1",
        "outputId": "ee416f6e-5bf3-4eb3-d718-21462c929bcd"
      },
      "source": [
        "from lib import has_pair_sum_max_cpp\n",
        "\n",
        "help(has_pair_sum_max_cpp)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on built-in function has_pair_sum_max_cpp in module lib:\n",
            "\n",
            "has_pair_sum_max_cpp(...) method of pybind11_builtins.pybind11_detail_function_record_v1_system_libstdcpp_gxx_abi_1xxx_use_cxx11_abi_1 instance\n",
            "    has_pair_sum_max_cpp(arg0: collections.abc.Sequence[typing.SupportsInt | typing.SupportsIndex]) -> bool\n",
            "\n",
            "    Check if two distinct elements in the list sum up to the list's maximum, excluding one instance of the maximum itself.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "has_pair_sum_max_cpp([23, 11, 12, 1, 2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSohRCfRCLZ9",
        "outputId": "80760d1b-ba95-4c88-884e-0bf761f9295a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create test case expectation criterion"
      ],
      "metadata": {
        "id": "VIjrChx2C0Xr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from enum import Enum\n",
        "\n",
        "from pyspark.sql import Row, DataFrame, SparkSession\n",
        "from pyspark.sql.types import (\n",
        "    StructType, StructField, StringType, IntegerType, ArrayType, BooleanType\n",
        ")\n",
        "\n",
        "\n",
        "class Stimpy(Enum):\n",
        "    \"\"\"\n",
        "    Enumerate the test case attributes for Stimpy.\n",
        "    \"\"\"\n",
        "\n",
        "    SAMPLE = [23, 11, 12, 1, 2]\n",
        "\n",
        "\n",
        "class SpongeBob(Enum):\n",
        "    \"\"\"\n",
        "    Enumerate the test case attributes for SpongeBob.\n",
        "    \"\"\"\n",
        "\n",
        "    SAMPLE = [10, 8, 12, 1, 3]\n",
        "\n",
        "\n",
        "class Zeldar(Enum):\n",
        "    \"\"\"\n",
        "    Enumerate the test case attributes for Zeldar.\n",
        "    \"\"\"\n",
        "\n",
        "    SAMPLE = [9, 7, 12, 1, 2]\n",
        "\n",
        "\n",
        "class Generator:\n",
        "    \"\"\"\n",
        "    Generate test data inputs and expectation for the test cases.\n",
        "    \"\"\"\n",
        "\n",
        "    data: DataFrame\n",
        "\n",
        "    def __init__(self, spark: SparkSession) -> None:\n",
        "        \"\"\"\n",
        "        Initialize the Generator with a SparkSession.\n",
        "        Args:\n",
        "            spark (SparkSession): A SparkSession instance.\n",
        "        \"\"\"\n",
        "        DATA = [\n",
        "            Row(\n",
        "                elements=employee.SAMPLE.value,\n",
        "                expected=has_pair_sum_max_cpp(employee.SAMPLE.value)\n",
        "            )\n",
        "            for employee in (Stimpy, SpongeBob, Zeldar)\n",
        "        ]\n",
        "\n",
        "        SCHEMA = StructType([\n",
        "            StructField(\"elements\", ArrayType(IntegerType()), False),\n",
        "            StructField(\"expected\", BooleanType(), False),\n",
        "        ])\n",
        "\n",
        "        self.data = spark.createDataFrame(data=DATA, schema=SCHEMA)\n"
      ],
      "metadata": {
        "id": "bWknxrB2vaJR"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.config(\n",
        "        key=\"spark.sql.execution.pythonUDF.arrow.enabled\", value=\"true\"\n",
        "    ).getOrCreate()\n",
        "\n",
        "Generator(spark).data.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2TKFAlPwnSw",
        "outputId": "0e5998ae-e775-4c8a-93f0-dd6e7c674dc8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+--------+\n",
            "|          elements|expected|\n",
            "+------------------+--------+\n",
            "|[23, 11, 12, 1, 2]|    true|\n",
            "| [10, 8, 12, 1, 3]|   false|\n",
            "|  [9, 7, 12, 1, 2]|   false|\n",
            "+------------------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Translate the C++ binding into a UDF"
      ],
      "metadata": {
        "id": "Up2G4Vw2DDsP"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dca9ce8a"
      },
      "source": [
        "from pandas import Series\n",
        "\n",
        "from pyspark.sql.functions import pandas_udf, col\n",
        "from pyspark.sql.types import BooleanType\n",
        "\n",
        "@pandas_udf(BooleanType())\n",
        "def checkMax(elements: Series) -> Series:\n",
        "    \"\"\"\n",
        "    Applies the C++ function to each array of integers in the pandas Series.\n",
        "    Args:\n",
        "        elements (pd.Series): A pandas Series containing arrays of integers.\n",
        "    Returns:\n",
        "        pd.Series: A pandas Series containing the results of the C++ function.\n",
        "    \"\"\"\n",
        "    return elements.apply(has_pair_sum_max_cpp)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compare actual udf with underlying C++  expectation"
      ],
      "metadata": {
        "id": "TqfzRK6oDU11"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1d577e6",
        "outputId": "f1a002f4-49c6-4d85-f3ed-ff046755f4b4"
      },
      "source": [
        "Generator(spark).data \\\n",
        ".withColumn(\"actual\", checkMax(\"elements\")) \\\n",
        ".show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+--------+------+\n",
            "|          elements|expected|actual|\n",
            "+------------------+--------+------+\n",
            "|[23, 11, 12, 1, 2]|    true|  true|\n",
            "| [10, 8, 12, 1, 3]|   false| false|\n",
            "|  [9, 7, 12, 1, 2]|   false| false|\n",
            "+------------------+--------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion\n",
        "\n",
        "Why bind C++ code?\n",
        "\n",
        "## Avoids Python Overhead\n",
        "\n",
        "Standard PySpark UDFs run in a separate Python process and require serialization/deserialization between JVM ↔ Python for every batch of rows.\n",
        "C++ code can be bound directly to Spark via JNI (Java Native Interface) or Arrow-based native execution, avoiding the Python interpreter entirely.\n",
        "\n",
        "\n",
        "\n",
        "## Vectorized Processing\n",
        "\n",
        "If you implement your C++ logic to process batches of data (e.g., via Apache Arrow columnar format), you can operate on entire arrays at once instead of row-by-row.\n",
        "This reduces function call overhead and leverages CPU cache locality.\n",
        "\n",
        "\n",
        "\n",
        "## SIMD & Low-Level Optimizations\n",
        "\n",
        "C++ allows use of SIMD intrinsics, memory pooling, and specialized algorithms that are not easily achievable in Python or even Java.\n",
        "You can also use optimized libraries like Eigen, Boost, or Intel MKL.\n",
        "\n",
        "\n",
        "\n",
        "## Better Memory Management\n",
        "\n",
        "C++ gives you control over allocation and reuse of buffers, reducing GC pressure in the JVM.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Typical Performance Gains\n",
        "\n",
        "Standard Python UDF → C++ bound UDF:\n",
        "5×–50× faster depending on:\n",
        "\n",
        "Size of data batches\n",
        "Complexity of computation\n",
        "Whether vectorization is used\n",
        "\n",
        "\n",
        "Pandas UDF (Arrow) → C++ bound UDF:\n",
        "Gains are smaller (maybe 2×–5×) because Pandas UDFs already use Arrow for batch transfer, but C++ still avoids Python’s runtime overhead.\n",
        "\n",
        "\n",
        "## Integration Approaches\n",
        "\n",
        "\n",
        "### JNI-based UDF (Java ↔ C++ binding)\n",
        "\n",
        "Write a Java wrapper that calls native C++ functions via System.loadLibrary.\n",
        "Register the Java method as a Spark SQL UDF.\n",
        "Best for tight integration and minimal overhead.\n",
        "\n",
        "\n",
        "\n",
        "### Apache Arrow Flight / Gandiva\n",
        "\n",
        "Use Arrow’s Gandiva engine to JIT-compile C++ expressions and run them inside Spark.\n",
        "Ideal for vectorized, columnar operations.\n",
        "\n",
        "\n",
        "\n",
        "### Spark Native Functions Plugin\n",
        "\n",
        "Implement as a Spark native expression in C++ and register it as a Catalyst expression.\n",
        "This is the fastest but requires modifying Spark internals.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### Example:\n",
        "#### JNI-bound C++ UDF\n",
        "Here’s a minimal example of binding C++ to Spark via Java:\n",
        "```cpp\n",
        "#include <jni.h>\n",
        "#include <cmath>\n",
        "\n",
        "extern \"C\" JNIEXPORT jdouble JNICALL\n",
        "Java_com_example_NativeLib_myUdf(JNIEnv* env, jobject obj, jdouble value) {\n",
        "    return std::sqrt(value) + 42.0; // Example computation\n",
        "}\n",
        "```\n",
        "\n",
        "#### Java Wrapper\n",
        "```java\n",
        "package Java.com.example;\n",
        "\n",
        "public class NativeLib {\n",
        "    static {\n",
        "        System.loadLibrary(\"native\"); // Loads libnative.so\n",
        "    }\n",
        "    public static native double myUdf(double value);\n",
        "}\n",
        "```\n",
        "\n",
        "#### Spark Registration\n",
        "```java\n",
        "spark.udf().register(\"myUdf\", (Double x) -> NativeLib.myUdf(x), DataTypes.DoubleType);\n",
        "```\n",
        "\n",
        "\n",
        "## Best Practices for Maximum Speed\n",
        "\n",
        "*   Batch process: Pass arrays/vectors to C++ instead of single values.\n",
        "\n",
        "*   Minimize JNI calls: JNI overhead per call can be high; process in chunks.\n",
        "*   Use Arrow columnar format for zero-copy data transfer.\n",
        "*   Preallocate buffers to avoid repeated allocations.\n",
        "*   Profile with realistic datasets before and after migration.\n",
        "\n",
        "If your Spark UDF is CPU-bound and currently implemented in Python, moving it to C++ via JNI or Arrow can yield order-of-magnitude performance improvements, especially if you process data in vectorized batches.\n"
      ],
      "metadata": {
        "id": "UdkuyFiFDnVN"
      }
    }
  ]
}